{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical MCMC for Polynomial Hyperelastic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data after Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [-0.019397538181166286,\n",
    "-0.03950739199689259,\n",
    "-0.06038278777575503,\n",
    "-0.08208157204829222,\n",
    "-0.10466668288087849,\n",
    "-0.12820667888715018,\n",
    "-0.15277633280785963,\n",
    "-0.17845729667032112,\n",
    "-0.2053388451756016,\n",
    "-0.23351870275250133]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize  FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fenics import *\n",
    "N=5\n",
    "from numpy import where\n",
    "\n",
    "mesh = UnitCubeMesh(N, N, N)\n",
    "V = VectorFunctionSpace(mesh, \"Lagrange\", 1)\n",
    "loadSteps = 10 \n",
    "delta = 0.02\n",
    "top =  CompiledSubDomain(\"near(x[2], side) && on_boundary\", side = 1.0)\n",
    "bottom = CompiledSubDomain(\"near(x[2], side) && on_boundary\", side = 0.0)\n",
    "c = Constant((0.0, 0.0, 0.0))\n",
    "bc_bottom = DirichletBC(V, c, bottom)\n",
    "vv = Function(V)\n",
    "bc = DirichletBC(V, Constant((0.0, 0.0, 1.0)), top)\n",
    "bc.apply(vv.vector())\n",
    "top_dofs = where(vv.vector()==1.0)[0]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "param = np.array([0.1,0.2,0.01,0.01])\n",
    "\n",
    "delta = np.linspace(0.02, 0.2,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first run an optimization in order to specify the priors knowledge.\n",
    "The model below is aversion of MacroModel which is ready for the oprimazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(delta,C01,C10,C11,D1):\n",
    "\n",
    "        ## Unwrap parameters\n",
    "\n",
    "    #C01 = param[0]\n",
    "    #C10 = param[1]\n",
    "    #C11 = param[2]\n",
    "    #D1 = param[3]\n",
    "\n",
    "        # Define functions\n",
    "    du = TrialFunction(V)            # Incremental displacement\n",
    "    v  = TestFunction(V)             # Test function\n",
    "    u  = Function(V)                 # Displacement from previous iteration\n",
    "\n",
    "        # Kinematics\n",
    "    d = u.geometric_dimension()\n",
    "    I = Identity(d)             # Identity tensor\n",
    "    F = I + grad(u)             # Deformation gradient\n",
    "    C = F.T*F                   # Right Cauchy-Green tensor\n",
    "\n",
    "        # Invariants of deformation tensors\n",
    "    I1 = tr(C)\n",
    "    J  = det(F)\n",
    "\n",
    "    I2 = 0.5 * ( I1**2 - tr(C * C))\n",
    "\n",
    "    barI1 = J**(-2./3.) * I1\n",
    "\n",
    "    barI2 = J**(-4./3.) * I2\n",
    "\n",
    "        # Stored strain energy density (compressible neo-Hookean model)\n",
    "    psi = C10 * (barI1 - 3.)  + C01 * (barI2 - 3.) + C11 * (barI1 - 3.) * (barI2 - 3.) + D1 * (J - 1.)**2\n",
    "\n",
    "        # Total potential energy\n",
    "    Pi = psi * dx\n",
    "\n",
    "        # Compute first variation of Pi (directional derivative about u in the direction of v)\n",
    "    F = derivative(Pi, u, v)\n",
    "\n",
    "        # Compute Jacobian of F\n",
    "    J = derivative(F, u, du)\n",
    "\n",
    "        # Loading loop\n",
    "    Force=[]\n",
    "    for i in range(0, len(delta)):\n",
    "                    # Update non-homogeneous boundary condition for current load step\n",
    "                r = Constant((0.0, 0.0, -delta[i]))\n",
    "                bc_top = DirichletBC(V, r, top)\n",
    "                bcs = [bc_bottom, bc_top]\n",
    "\n",
    "                    # Solve variational problem\n",
    "                solve(F == 0, u, bcs, J=J)\n",
    "\n",
    "                    \n",
    "\n",
    "                    # Output forces\n",
    "                y = assemble(F)\n",
    "                Force_top = 0\n",
    "                for i in top_dofs:\n",
    "                    Force_top += y[i]\n",
    "\n",
    "                #print(Force_top)\n",
    "                Force.append(Force_top)\n",
    "\n",
    "    return np.array(Force)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the optimazation with starting points of the parameters [20,20,20,20]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "popt,pcov = curve_fit(model,delta,data,p0=np.asarray([20,20,20,20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical MCMC for comperession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Gen_data1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c89f9944960a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mGen_data1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Gen_data1'"
     ]
    }
   ],
   "source": [
    "from fenics import *\n",
    "\n",
    "from numpy import where\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rnd\n",
    "###############################################################################\n",
    "from smt.sampling_methods import LHS\n",
    "from emukit.model_wrappers.gpy_quadrature_wrappers import BaseGaussianProcessGPy, RBFGPy\n",
    "from emukit.quadrature.kernels.integration_measures import IsotropicGaussianMeasure\n",
    "from emukit.quadrature.kernels import QuadratureRBFIsoGaussMeasure\n",
    "from emukit.quadrature.methods.vanilla_bq import VanillaBayesianQuadrature\n",
    "import GPy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import truncnorm\n",
    "import math\n",
    "from emukit.core.loop.user_function import UserFunctionWrapper\n",
    "import random as rnd\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List, Optional\n",
    "from scipy.stats import norm\n",
    "import _pickle as cPickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro Model for Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MacroModel():\n",
    "\n",
    "    def __init__(self, N = 5):\n",
    "\n",
    "        self.mesh = UnitCubeMesh(N, N, N)\n",
    "\n",
    "        self.V = VectorFunctionSpace(self.mesh, \"Lagrange\", 1)\n",
    "        \n",
    "        self.loadSteps = 10   # cube [1,1,1] is pressed by 0.2 on top\n",
    "        self.delta = 0.02\n",
    "        self.N_MC = 30\n",
    "        self.verbosity = True\n",
    "\n",
    "        # Find the top and bottom of my domain\n",
    "        self.top =  CompiledSubDomain(\"near(x[2], side) && on_boundary\", side = 1.0)\n",
    "        self.bottom = CompiledSubDomain(\"near(x[2], side) && on_boundary\", side = 0.0)\n",
    "        self.c = Constant((0.0, 0.0, 0.0))\n",
    "        self.bc_bottom = DirichletBC(self.V, self.c, self.bottom) #boundary for bottom face = fixed\n",
    "\n",
    "        # Find dofs on top face\n",
    "        #ff = MeshFunction(\"size_t\",mesh, mesh.topology().dim()-1, 0)\n",
    "        #top.mark(ff, 1)\n",
    "        self.vv = Function(self.V)\n",
    "        self.bc = DirichletBC(self.V, Constant((0.0, 0.0, 1.0)), self.top)\n",
    "        self.bc.apply(self.vv.vector())\n",
    "        self.top_dofs = where(self.vv.vector()==1.0)[0]\n",
    "\n",
    "    def setData(self, data, sigma_f):\n",
    "        self.data = data\n",
    "        self.sigma_f = sigma_f\n",
    "        self.J = len(data)\n",
    "\n",
    "\n",
    "    def apply(self, data, param, plotSolution = False, solutionFileName = \"solution\"):\n",
    "\n",
    "        ## Unwrap parameters\n",
    "\n",
    "        C01 = param[0]\n",
    "        C10 = param[1]\n",
    "        C11 = param[2]\n",
    "        D1 = param[3]\n",
    "\n",
    "        # Define functions\n",
    "        du = TrialFunction(self.V)            # Incremental displacement\n",
    "        v  = TestFunction(self.V)             # Test function\n",
    "        u  = Function(self.V)                 # Displacement from previous iteration\n",
    "\n",
    "        # Kinematics\n",
    "        d = u.geometric_dimension()\n",
    "        I = Identity(d)             # Identity tensor\n",
    "        F = I + grad(u)             # Deformation gradient\n",
    "        C = F.T*F                   # Right Cauchy-Green tensor\n",
    "\n",
    "        # Invariants of deformation tensors\n",
    "        I1 = tr(C)\n",
    "        J  = det(F)\n",
    "\n",
    "        I2 = 0.5 * ( I1**2 - tr(C * C))\n",
    "\n",
    "        barI1 = J**(-2./3.) * I1\n",
    "\n",
    "        barI2 = J**(-4./3.) * I2\n",
    "\n",
    "        # Stored strain energy density (compressible neo-Hookean model)\n",
    "        psi = C10 * (barI1 - 3.)  + C01 * (barI2 - 3.) + C11 * (barI1 - 3.) * (barI2 - 3.) + D1 * (J - 1.)**2\n",
    "\n",
    "        # Total potential energy\n",
    "        Pi = psi * dx\n",
    "\n",
    "        # Compute first variation of Pi (directional derivative about u in the direction of v)\n",
    "        F = derivative(Pi, u, v)\n",
    "\n",
    "        # Compute Jacobian of F\n",
    "        J = derivative(F, u, du)\n",
    "\n",
    "        # Loading loop\n",
    "        Force=[]\n",
    "        for i in range(1, self.loadSteps + 1):\n",
    "\n",
    "                    if(self.verbosity):\n",
    "                        print(\"Load step - \" + str(i))\n",
    "\n",
    "                    # Update non-homogeneous boundary condition for current load step\n",
    "                    r = Constant((0.0, 0.0, -i * self.delta))\n",
    "                    bc_top = DirichletBC(self.V, r, self.top)\n",
    "                    bcs = [self.bc_bottom, bc_top]\n",
    "\n",
    "                    # Solve variational problem\n",
    "                    solve(F == 0, u, bcs, J=J)\n",
    "\n",
    "                    # Save solution in VTK format\n",
    "                    if(plotSolution):\n",
    "                        file = File(solutionFileName + str(i) + \".pvd\");\n",
    "                        file << u;\n",
    "\n",
    "                    # Output forces\n",
    "                    y = assemble(F)\n",
    "                    Force_top = 0\n",
    "                    for i in self.top_dofs:\n",
    "                        Force_top += y[i]\n",
    "\n",
    "                    print(Force_top)\n",
    "                    Force.append(Force_top)\n",
    "\n",
    "        #\n",
    "        assert len(Force) == len(data), \"Force list not same length as data list\"\n",
    "\n",
    "        #return -np.sum((np.asarray(Force) - np.asarray(self.data))**2)/ (2.0 * self.sigma_f**2)\n",
    "        Phi = -np.sum((np.asarray(Force) - np.asarray(data))**2)/ (2.0 * self.sigma_f**2)\n",
    "        #return np.exp(Phi)\n",
    "        return Phi\n",
    "        \n",
    "    def evaluateDensity(self, misfit):\n",
    "        return -0.5 * np.sum(misfit)**2 / (self.sigmaf**2)\n",
    "##############################################################################################################\n",
    "    def press_fem(self) -> Tuple[UserFunctionWrapper, List[Tuple[float, float]]]:\n",
    "        \n",
    "        integral_bound = [(1,15),(0.2,0.4)]\n",
    "        return UserFunctionWrapper(self._press_fem), integral_bound\n",
    "\n",
    "    def _press_fem(self, data,param:np.ndarray) -> np.ndarray:\n",
    "        Likelihood=self.apply(data, param)\n",
    "        return np.reshape(np.array(Likelihood),(-1,1))\n",
    "##############################################################################################################\n",
    "    def singleGP(self, data):\n",
    "        #########################################\n",
    "        xlimits = np.array([[0,0.2], [0,0.3],[0,0.2],[0,0.3]])   #for polynomial Mooney Rivlin\n",
    "        sampling = LHS(xlimits=xlimits)\n",
    "\n",
    "        train_number =300\n",
    "        theta = sampling(train_number)        \n",
    "        ########################################\n",
    "        \n",
    "        self.X_init=np.zeros((train_number,4))\n",
    "        Y=[]\n",
    "        for i in range(0,train_number):                #initial points to GP \n",
    "                function_input=theta[i]\n",
    "                self.X_init[i]=theta[i]\n",
    "                Y_= np.reshape(user_function.f(data, function_input),(-1,1))\n",
    "                Y.append(Y_)\n",
    "            \n",
    "        self.Y_init=np.reshape(np.array(Y),(-1,1))\n",
    "\n",
    "        gpy_model = GPy.models.GPRegression(X=self.X_init, Y=self.Y_init,kernel=GPy.kern.Matern52(input_dim=self.X_init.shape[1], ARD=False))  \n",
    "       \n",
    "        gpy_model.optimize(messages=True)\n",
    "        gpy_model.optimize_restarts(num_restarts = 1)\n",
    "\n",
    "        return gpy_model\n",
    "    \n",
    "  \n",
    "    def trainAll(self):\n",
    "        \n",
    "        self.GPs=[]\n",
    "        \n",
    "        for j in range(0,self.J):\n",
    "            GP=self.singleGP(self.data[j])\n",
    "            self.GPs.append(GP)\n",
    "        return self.GPs  \n",
    "\n",
    "#################################################################################################################\n",
    "    def theta_given_phi(self, phi, theta):\n",
    "        return norm.logpdf(theta[0], loc=phi[0], scale=phi[1]) + norm.logpdf(theta[1], loc=phi[2], scale=phi[3]) + norm.logpdf(theta[2], loc=phi[4], scale=phi[5]) + norm.logpdf(theta[3], loc=phi[6], scale=phi[7])\n",
    "\n",
    "    def logLike(self,phi):\n",
    "        ll = 0.0\n",
    "        for j in range(self.J): # For each experiment\n",
    "            tmp = 0.0\n",
    "            for i in range(self.N_MC):\n",
    "                theta =np.array( [np.random.normal(phi[0],phi[1]),np.random.normal(phi[2],phi[3]),np.random.normal(phi[4],phi[5]),np.random.normal(phi[6],phi[7])]) \n",
    "                gp_theta=np.reshape(theta,(1,-1))\n",
    "                part1 =self.GPs[j].predict(gp_theta) \n",
    "                part2  = self.theta_given_phi(phi, theta)\n",
    "                #tmp+=float(part1[0])  *part2                        \n",
    "                tmp+=float(part1[0])  + np.log(part2)\n",
    "            if tmp<=0:\n",
    "                tmp=0.01\n",
    "            #ll += np.log(tmp/self.N_MC)\n",
    "            ll += tmp/self.N_MC\n",
    "        return ll             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadSteps = 10\n",
    "delta = 0.02\n",
    "saveSolution = True\n",
    "verbosity = True\n",
    "\n",
    "Data_compression = cPickle.load( open( \"CompressionData.p\", \"rb\" ) )\n",
    "myModel = MacroModel()\n",
    "myModel.setData(Data_compression,0.1)\n",
    "user_function, integral_bounds = myModel.press_fem()\n",
    "tr=myModel.trainAll()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndraws = 3000  # number of draws from the distribution\n",
    "phi=np.zeros((ndraws,8))\n",
    "#theta=np.zeros((1,2))\n",
    "prop_phi=np.zeros((ndraws,8))\n",
    "sigma1_sq=np.zeros((ndraws,1))\n",
    "sigma2_sq=np.zeros((ndraws,1))\n",
    "a=[1]\n",
    "sigma1_sq[0]=1\n",
    "sigma1_sq_it=1\n",
    "k=0\n",
    "ni=0\n",
    "m=1.1\n",
    "a_star=0.60\n",
    "acceptanceCount=0\n",
    "phi[0]=[1,1,1,1,1,1,1,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logLikelihood = myModel.logLike(phi[0])\n",
    "\n",
    "for it in range(1,ndraws):\n",
    "    prop_phi[it][0]=np.sqrt(1-sigma1_sq_it**2)*phi[it-1][0] + 0.1*sigma1_sq_it*float(truncnorm.rvs(-1,1,size=1))    \n",
    "    prop_phi[it][1]=np.sqrt(1-sigma1_sq_it**2)*phi[it-1][1] + 0.01*sigma1_sq_it*float(truncnorm.rvs(-1,1,size=1))\n",
    "    prop_phi[it][2]=np.sqrt(1-sigma1_sq_it**2)*phi[it-1][2] + 0.2*sigma1_sq_it*float(truncnorm.rvs(-1,1,size=1))\n",
    "    prop_phi[it][3]=np.sqrt(1-sigma1_sq_it**2)*phi[it-1][3] + 0.01*sigma1_sq_it*float(truncnorm.rvs(-1,1,size=1))\n",
    "    prop_phi[it][4]=np.sqrt(1-sigma1_sq_it**2)*phi[it-1][4] + 0.09*sigma1_sq_it*float(truncnorm.rvs(-1,1,size=1))    \n",
    "    prop_phi[it][5]=np.sqrt(1-sigma1_sq_it**2)*phi[it-1][5] + 0.01*sigma1_sq_it*float(truncnorm.rvs(-1,1,size=1))\n",
    "    prop_phi[it][6]=np.sqrt(1-sigma1_sq_it**2)*phi[it-1][6] + 0.1*sigma1_sq_it*float(truncnorm.rvs(-1,1,size=1))\n",
    "    prop_phi[it][7]=np.sqrt(1-sigma1_sq_it**2)*phi[it-1][7] + 0.01*sigma1_sq_it*float(truncnorm.rvs(-1,1,size=1))\n",
    "    \n",
    "    \n",
    "    prop_phi[it]=abs(prop_phi[it])\n",
    "    \n",
    "    #############################    \n",
    "#update the adaptation\n",
    "    if it>100*(ni+1):\n",
    "        k=k+1\n",
    "        ni=ni+1\n",
    "        #update of sigma_sq\n",
    "        log_sigma1_sq=np.log(sigma1_sq[k-1]) + m**(-k)*(np.mean(np.array([a]))-a_star)\n",
    "        sigma1_sq[k]=np.exp(log_sigma1_sq)\n",
    "        sigma1_sq_it=float(sigma1_sq[k]) \n",
    "\n",
    "    ##############################\n",
    "    prop_logLikelihood = myModel.logLike(prop_phi[it])\n",
    "\n",
    "\n",
    "    alpha= prop_logLikelihood -logLikelihood\n",
    "    alpha = min(0,alpha)\n",
    "            \n",
    "    \n",
    "    if     np.log(rnd.random())<alpha:\n",
    "    \n",
    "           acceptanceCount=acceptanceCount+1\n",
    "           phi[it]=prop_phi[it]\n",
    "           logLikelihood=prop_logLikelihood\n",
    "           a=a+[1]\n",
    "    else:\n",
    "           phi[it]=phi[it-1]\n",
    "           a=a+[0]\n",
    "           \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
